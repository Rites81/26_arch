{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1519ae9f",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54434871",
   "metadata": {},
   "source": [
    "## Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an example of each."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89d8644",
   "metadata": {},
   "source": [
    "### Simple linear regression - Simple linear regression is a relation between dependent variable(Y) and independent variable(X). The relation represent a straight line.\n",
    "           Equation = (Y = b0 + b1*X + ε)\n",
    "   ##### Example: Suppose you want to predict a person's weight (Y) based on their height (X).\n",
    "        \n",
    "### Multiple linear regression - In multiple linear regression there is more than one independent variable. It models the relation between a dependent variable(Y).\n",
    "     Equation = (Y = b0 + b1X1 + b2X2 + ... + bn*Xn + ε) \n",
    "   #### Example = In this case, size, number of bedrooms, and distance are the independent variables, and you are assuming a linear relationship between these variables and the house price"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd08b27",
   "metadata": {},
   "source": [
    "## Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in a given dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c25d8c",
   "metadata": {},
   "source": [
    "#### Linearity: The relationship between the dependent and independent variables is linear.\n",
    "#### Independence: The observations are independent of each other.\n",
    "#### Homoscedasticity: The variance of the errors is constant across all levels of the independent variables.\n",
    "#### Normality: The errors follow a normal distribution.\n",
    "#### No multicollinearity: The independent variables are not highly correlated with each other.\n",
    "#### No endogeneity: There is no relationship between the errors and the independent variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d906b7f5",
   "metadata": {},
   "source": [
    "## Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using a real-world scenario."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121d3ec4",
   "metadata": {},
   "source": [
    "Slope and intercept can help you model real-world scenarios by showing how one variable depends on another variable in a linear way. For example, if you want to model how the cost of renting a car depends on the number of days, you can use a linear equation with slope and intercept. The slope represents the rate of change of the cost per day, and the intercept represents the fixed fee or deposit. If you know that renting a car costs $25 per day plus a $100 deposit, you can write the equation as y = 25x + 100, where y is the cost and x is the number of days. You can then use the equation, graph, or table to find the cost for any number of days, or the number of days for any cost."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc66cbf3",
   "metadata": {},
   "source": [
    "## Q4. Explain the concept of gradient descent. How is it used in machine learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0f8a6e3",
   "metadata": {},
   "source": [
    "#### Gradient Decent is a optimizing algorithum used to minimize the cost function or loss function assosiated with ML model.\n",
    "### There are two main variants of gradient descent:\n",
    " #### 1. Batch Gradient Descent: Computes the gradient of the entire dataset and updates the parameters after processing the entire dataset in each iteration. It provides accurate results but can be computationally expensive for large datasets.\n",
    " #### 2. Stochastic Gradient Descent (SGD): Computes the gradient and updates the parameters for each individual data point. It is computationally less expensive and more suitable for large datasets, but the updates can be noisy.\n",
    " #### 3. Mini-Batch Gradient Descent: Strikes a balance between batch and stochastic gradient descent by updating the parameters based on a randomly selected subset (mini-batch) of the data.  \n",
    "    \n",
    "    \n",
    "   ## Use in Machine Learning:\n",
    "\n",
    "Gradient descent is a fundamental optimization algorithm used in various machine learning tasks, especially for training models. It is employed to find the optimal parameters (weights and biases) that minimize the difference between the predicted output and the actual output (the cost function). This optimization process is essential in training models for tasks such as linear regression, logistic regression, neural networks, and many other supervised learning algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0a4597c",
   "metadata": {},
   "source": [
    "## Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549b92b",
   "metadata": {},
   "source": [
    "#### Multiple linear regression is an extension of simple linear regression, allowing for the examination of the relationship between a dependent variable and multiple independent variables. The model is expressed as:\n",
    "    Equation = (Y = b0 + b1X1 + b2X2 + ... + bn*Xn + ε)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d3bb79",
   "metadata": {},
   "source": [
    "## Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and address this issue?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab71d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d0f45bd",
   "metadata": {},
   "source": [
    "## Q7. Describe the polynomial regression model. How is it different from linear regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736dbd2f",
   "metadata": {},
   "source": [
    "## Polynomial Regression:\n",
    "\n",
    "###### Equation: (Y = b0 + b1X1 + b2X2 + ... + bn*Xn + ε)\n",
    "###### Model: Allows for fitting a polynomial function (e.g., quadratic, cubic) to the data.\n",
    "###### Degree: Represents the highest power of the independent variable in the model.\n",
    "###### Use: Captures nonlinear relationships in the data.\n",
    "    \n",
    "##  Difference from Linear Regression:\n",
    "        \n",
    "###### Linear Regression: Assumes a linear relationship between the independent and dependent variables.\n",
    "###### Polynomial Regression: Accommodates nonlinear relationships by introducing higher-order terms (e.g., \n",
    "###### Flexibility: Polynomial regression can capture more complex patterns in the data compared to the linearity assumed in linear regression.    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7586a607",
   "metadata": {},
   "source": [
    "## Q8. What are the advantages and disadvantages of polynomial regression compared to linear regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deae225b",
   "metadata": {},
   "source": [
    "## Advantages of Polynomial Regression:\n",
    "\n",
    "Captures Nonlinear Relationships: Polynomial regression can model complex, nonlinear patterns that linear regression cannot represent.\n",
    "\n",
    "Flexible Modeling: It provides flexibility in fitting curves to the data, allowing for a better fit to intricate relationships.\n",
    "\n",
    "Disadvantages of Polynomial Regression:\n",
    "\n",
    "Overfitting: High-degree polynomials can lead to overfitting, capturing noise in the data rather than the underlying pattern.\n",
    "\n",
    "Interpretability: As the degree of the polynomial increases, the model becomes more complex, making it harder to interpret the individual effects of variables.\n",
    "\n",
    "Increased Variance: Higher-degree polynomials can introduce more variability in the model, making predictions less stable.\n",
    "\n",
    "## Use Cases for Polynomial Regression:\n",
    "\n",
    "Nonlinear Relationships: When the relationship between the variables is clearly nonlinear and cannot be adequately captured by a linear model.\n",
    "\n",
    "Complex Patterns: In situations where the data exhibits intricate patterns or curves that a linear model cannot represent.\n",
    "\n",
    "Experimental Data: In experimental settings where the true nature of the relationship is not known, polynomial regression can be used to explore potential nonlinearities.\n",
    "\n",
    "Prefer to Use Polynomial Regression When:\n",
    "\n",
    "Visual Inspection Suggests Nonlinearity: If a scatter plot of the data shows a curvilinear pattern, polynomial regression might be more appropriate.\n",
    "\n",
    "Model Fit Improvement: When adding polynomial terms significantly improves the model fit based on metrics like R-squared or cross-validation.\n",
    "\n",
    "Balance between Bias and Variance: Choosing an appropriate degree of the polynomial helps balance bias and variance, avoiding overfitting while capturing essential nonlinearities.\n",
    "\n",
    "Practical Considerations: When the assumptions of linear regression are violated, and transforming variables or using a polynomial term improves model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f57be4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
